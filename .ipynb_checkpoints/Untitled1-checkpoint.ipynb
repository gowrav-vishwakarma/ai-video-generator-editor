{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265690b3-a5a5-4160-9b18-883ec7d9cad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49a50e29f324a648e33ace6d7eeb300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057eec1161364d8d90e951fb57a8999b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f998b8c50c4d64b8734354c9c64787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317e82de6efa4ad4bde3e933e3ea39af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d00fc7385940b985d462fce0e5c50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ship.mp4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import BitsAndBytesConfig as DiffusersBitsAndBytesConfig, LTXVideoTransformer3DModel, LTXPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "from transformers import BitsAndBytesConfig as BitsAndBytesConfig, T5EncoderModel\n",
    "\n",
    "# torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "text_encoder_8bit = T5EncoderModel.from_pretrained(\n",
    "    \"Lightricks/LTX-Video\",\n",
    "    subfolder=\"text_encoder\",\n",
    "    quantization_config=quant_config,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "quant_config = DiffusersBitsAndBytesConfig(load_in_8bit=True)\n",
    "transformer_8bit = LTXVideoTransformer3DModel.from_pretrained(\n",
    "    \"Lightricks/LTX-Video\",\n",
    "    subfolder=\"transformer\",\n",
    "    quantization_config=quant_config,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "pipeline = LTXPipeline.from_pretrained(\n",
    "    \"Lightricks/LTX-Video\",\n",
    "    text_encoder=text_encoder_8bit,\n",
    "    transformer=transformer_8bit,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"balanced\",\n",
    ")\n",
    "\n",
    "prompt = \"An elderly gentleman, with a serene expression, sits at the water's edge, a steaming cup of tea by his side. He is engrossed in his artwork, brush in hand, as he renders an oil painting on a canvas that's propped up against a small, weathered table. The sea breeze whispers through his silver hair, gently billowing his loose-fitting white shirt, while the salty air adds an intangible element to his masterpiece in progress. The scene is one of tranquility and inspiration, with the artist's canvas capturing the vibrant hues of the setting sun reflecting off the tranquil sea.\"\n",
    "prompt = \"A woman with long brown hair and light skin smiles at another woman with long blonde hair. The woman with brown hair wears a black jacket and has a small, barely noticeable mole on her right cheek. The camera angle is a close-up, focused on the woman with brown hair's face. The lighting is warm and natural, likely from the setting sun, casting a soft glow on the scene. The scene appears to be real-life footage.\"\n",
    "prompt = \"A man walks towards a window, looks out, and then turns around. He has short, dark hair, dark skin, and is wearing a brown coat over a red and gray scarf. He walks from left to right towards a window, his gaze fixed on something outside. The camera follows him from behind at a medium distance. The room is brightly lit, with white walls and a large window covered by a white curtain. As he approaches the window, he turns his head slightly to the left, then back to the right. He then turns his entire body to the right, facing the window. The camera remains stationary as he stands in front of the window. The scene is captured in real-life footage.\"\n",
    "prompt = \"a garden scene with park benches and a man sitting on a bench, closed eyes, short, dark hair, dark skin, wearing a brown coat over a red and gray scarf. camera zooms into person and stops with him in focus. then he calmly opens his eys, smiles and stands up. The scene is captured in real-life footage.\"\n",
    "\n",
    "video = pipeline(prompt=prompt, num_frames=161, num_inference_steps=50).frames[0]\n",
    "export_to_video(video, \"ship.mp4\", fps=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e4d866-2152-411f-a5ba-5c59f3b7603b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f20b0d77d440e89e8b6cd44946062e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2a0bac2f7f4ea6947652e2b8ae3308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded image from ./instagram_content/scene_0_keyframe.png of type: <class 'PIL.Image.Image'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd5a362bece489fa73e19d1ecfc438a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video exported to ship.mp4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import AutoencoderKLLTXVideo, LTXImageToVideoPipeline, LTXVideoTransformer3DModel\n",
    "from diffusers.utils import export_to_video, load_image # Import load_image\n",
    "\n",
    "# `single_file_url` could also be https://huggingface.co/Lightricks/LTX-Video/ltx-video-2b-v0.9.1.safetensors\n",
    "single_file_url = \"https://huggingface.co/Lightricks/LTX-Video/ltx-video-2b-v0.9.safetensors\"\n",
    "\n",
    "# Determine device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# It's good practice to move models to the device\n",
    "transformer = LTXVideoTransformer3DModel.from_single_file(\n",
    "  single_file_url, torch_dtype=torch.bfloat16\n",
    ").to(device)\n",
    "vae = AutoencoderKLLTXVideo.from_single_file(single_file_url, torch_dtype=torch.bfloat16).to(device)\n",
    "pipe = LTXImageToVideoPipeline.from_pretrained(\n",
    "  \"Lightricks/LTX-Video\", transformer=transformer, vae=vae, torch_dtype=torch.bfloat16\n",
    ").to(device)\n",
    "\n",
    "\n",
    "prompt = \"A person meditating in a garden, calmly opens his eys, smiles and standup, goes to his car and opens door.\"\n",
    "\n",
    "# Load the image first\n",
    "image_path = \"./instagram_content/scene_0_keyframe.png\"\n",
    "try:\n",
    "    input_image = load_image(image_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Image file not found at {image_path}\")\n",
    "    print(\"Please ensure the image exists at the specified path.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading image: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Successfully loaded image from {image_path} of type: {type(input_image)}\")\n",
    "\n",
    "video = pipe(\n",
    "    image = input_image, # Pass the loaded image object\n",
    "    prompt=prompt,\n",
    "    num_frames=161, # Default is 161, can be adjusted\n",
    "    num_inference_steps=50, # Default is 50\n",
    "    # You might want to specify height and width if your input image is not the default expected size\n",
    "    # height=480, # Example, default is 480 for this model\n",
    "    # width=704,  # Example, default is 704 for this model\n",
    ").frames[0]\n",
    "\n",
    "output_video_path = \"ship.mp4\"\n",
    "export_to_video(video, output_video_path, fps=24)\n",
    "print(f\"Video exported to {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a8876-99f6-467d-b8d9-bac4dfecbc97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
